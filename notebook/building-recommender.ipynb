{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config('spark.driver.memory', '15g') \\\n",
    "    .appName('cafe-build-recommender') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datasets_path = os.path.join('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_file = os.path.join(datasets_path, 'rating.csv')\n",
    "ratings_raw_data = sc.textFile(rating_file)\n",
    "ratings_raw_data_header = ratings_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_data = ratings_raw_data.filter(lambda line: line != ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\"))\\\n",
    "    .map(lambda tokens: (tokens[1], tokens[0].replace(\"-\", \"\"), tokens[2])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '5610000104201900272', '10'),\n",
       " ('1', '5610000104201900212', '10'),\n",
       " ('1', '3770000104201900160', '10')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터순서: (유저ID, 카페ID, LIKE)\n",
    "(3760000-104-2019-00185) 이런식의 카페 ID 에서 -를 삭제해서 사용한다.\n",
    "(7)-(3)-(4)-(5) 형태의 총 19 자리의 관리번호."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5610000104201800133', '커피에반하다영통구청2호점'),\n",
       " ('3770000104201900191', '시에커피(sie coffee)'),\n",
       " ('3760000104201900185', '날쌘카페(탑동점)')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cafe_file = os.path.join(datasets_path, 'data.csv')\n",
    "\n",
    "cafe_raw_data = sc.textFile(cafe_file)\n",
    "cafe_raw_data_header = cafe_raw_data.take(1)[0]\n",
    "\n",
    "headerList = str(cafe_raw_data_header).split(\",\") # 관리번호 = PK\n",
    "need_column = ['관리번호', '영업상태구분코드', '영업상태명', '소재지전화',\\\n",
    "        '소재지면적','소재지전체주소', '도로명전체주소', '사업장명', '최종수정시점',\\\n",
    "        '업태구분명', '좌표정보(X)', '좌표정보(Y)', '시설총규모', '홈페이지']\n",
    "need_column_index = []\n",
    "column_list = []\n",
    "for i, value in enumerate(headerList):\n",
    "    if str(value) in need_column:\n",
    "        need_column_index.append(i)\n",
    "        column_list.append(str(value))\n",
    "\n",
    "cafe_data = cafe_raw_data.filter(lambda line: line!=cafe_raw_data_header) \\\n",
    "    .map(lambda line: line.split(\",\")) \\\n",
    "    .filter(lambda tokens: tokens[24] == '커피숍' and tokens[7] =='영업/정상')\\\n",
    "    .map(lambda tokens: [tokens[i] for i in need_column_index]) \\\n",
    "    .filter(lambda tokens: tokens[5].split()[0] == '경기도' or tokens[5].split()[0] == '충청북도')\\\n",
    "    .map(lambda tokens: (tokens[0].replace(\"-\", \"\"), tokens[7]))\n",
    "\n",
    "cafe_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지 데이터 세팅 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users : ['1', '4', '8']\n",
      "items : ['3760000104201900173', '3760000104201900158', '3750000104201900109']\n",
      "[('1', '5610000104201900272', '10'), ('1', '5610000104201900212', '10'), ('1', '3770000104201900160', '10')]\n",
      "[('5610000104201900272', ('1', '10')), ('5610000104201900212', ('1', '10')), ('3770000104201900160', ('1', '10'))]\n",
      "[('1', 10661, '10'), ('2', 10661, '10'), ('3', 10661, '10')]\n"
     ]
    }
   ],
   "source": [
    "###### cafe 데이터 integer mapping #######\n",
    "\n",
    "users = ratings_data.map(lambda r: r[0]).distinct()\n",
    "items = cafe_data.map(lambda r: r[0]).distinct()\n",
    "\n",
    "print(\"users :\", users.take(3))\n",
    "print(\"items :\", items.take(3))\n",
    "\n",
    "# Zips the RDDs and creates 'mirrored' RDDs to facilitate reverse mapping \n",
    "user_int = users.zipWithIndex()\n",
    "int_user = user_int.map(lambda u: (u[1], u[0]))\n",
    "item_int = items.zipWithIndex()\n",
    "int_item = item_int.map(lambda i: (i[1], i[0]))\n",
    "\n",
    "print(ratings_data.take(3))\n",
    "\n",
    "ratings = ratings_data.map(lambda r: (r[1], (r[0], r[2])))\n",
    "print(ratings.take(3))\n",
    "ratings = ratings.join(item_int).map(lambda r: (r[1][0][0], r[1][1], r[1][0][1]))\n",
    "print(ratings.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "integer_map_list << ALS 에서 training_RDD 의 값이 integer 만 사용가능해서 mapping 한 데이터를 사용해서 ratings 의 값들을 integer 값으로 변경."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, validation_RDD, test_RDD = ratings.randomSplit([6, 2, 2], seed=0)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x:(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 10661, '10'), ('2', 10661, '10')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_RDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 1 the RMSE is 0.05144809643752524\n",
      "For rank 4 the RMSE is 0.03618933289488169\n",
      "For rank 8 the RMSE is 0.03666640977318992\n",
      "For rank 10 the RMSE is 0.036880709892221475\n",
      "For rank 12 the RMSE is 0.035303254245323455\n",
      "For rank 16 the RMSE is 0.03756299087562722\n",
      "The best model was trained with rank 12\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 10\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [1, 4, 8, 10, 12, 16]\n",
    "errors = [0, 0, 0, 0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations, lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print('For rank %s the RMSE is %s' % (rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print('The best model was trained with rank %s' % best_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((42, 3558), 9.962437001192278), ((126, 3558), 9.962437001192278), ((115, 3558), 9.962437001192278)]\n",
      "[((145, 10687), (10.0, 9.962437001192278)), ((161, 10695), (10.0, 9.962437015639482)), ((1, 5295), (10.0, 9.962437015639482))]\n"
     ]
    }
   ],
   "source": [
    "print(predictions.take(3))\n",
    "print(rates_and_preds.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.03530325422218386\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 10661, 10.0), (2, 10661, 10.0)]\n",
      "There are 578360 recommendations in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "# Parse\n",
    "complete_ratings_data = ratings.map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache() \n",
    "print(complete_ratings_data.take(2)) # userId, cafe_id (mapping), like.\n",
    "print(\"There are %s recommendations in the complete dataset\" % (complete_ratings_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5296, 37), (5424, 41), (10840, 39)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "# cafe_id, like > group By key (key = 카페아이디)\n",
    "cafe_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey()) \n",
    "cafe_ID_with_avg_ratings_RDD = cafe_ID_with_ratings_RDD.map(get_counts_and_averages) # 결과 = (카페ID, (평가받은 수, 평가 평균))\n",
    "cafe_rating_counts_RDD = cafe_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))\n",
    "\n",
    "cafe_rating_counts_RDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 유저의 레이팅을 추가해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 157, 10), (0, 5347, 10), (0, 5357, 10), (0, 8106, 10), (0, 10828, 10), (0, 165, 10), (0, 33, 10), (0, 5407, 10), (0, 5366, 10), (0, 10690, 10)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "new_user_ID = 0\n",
    "new_user_ratings = []\n",
    "ratings = ['3760000-104-2014-00043', '3760000-104-2012-00063', '3770000-104-2019-00087', '3760000-104-2019-00062', '3760000-104-2014-00177', '3760000-104-2014-00019', '3760000-104-2018-00014', '3760000-104-2020-00022', '3760000-104-2016-00083', '3760000-104-2014-00021', '3760000-104-2017-00150', '3760000-104-2011-00046', '3760000-104-2019-00050']\n",
    "for i in range(len(ratings)):\n",
    "    # index = random.randrange(0, 16000)\n",
    "    new_user_ratings.append((new_user_ID, str(ratings[i]).replace(\"-\", \"\"), 10))\n",
    "\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "new_user_ratings_RDD = new_user_ratings_RDD.map(lambda r: (r[1], (r[0], r[2]))).join(item_int).map(lambda r: (r[1][0][0], r[1][1], r[1][0][1]))\n",
    "\n",
    "print('New user ratings: %s' % new_user_ratings_RDD.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model trained in 23.941 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print(\"New model trained in %s seconds\" % round(tt,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_cafe_RDD = (cafe_ID_with_ratings_RDD.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_cafe_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(130, ((9.945325189734302, 10679), 36)),\n",
       " (130, ((9.945325189734302, 10702), 36)),\n",
       " (130, ((9.945325189734302, 5295), 36))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_ratings_data).join(cafe_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended cafe (with more than 25 reviews):\n",
      "(10679, 9.945325189734302, 36)\n",
      "(10702, 9.945325189734302, 36)\n",
      "(5295, 9.945325189734302, 36)\n",
      "(43, 9.945325189734302, 36)\n",
      "(5305, 9.945325189734302, 36)\n",
      "(10730, 9.945325189734302, 36)\n",
      "(10764, 9.945325189734302, 36)\n",
      "(116, 9.945325189734302, 36)\n",
      "(5399, 9.945325189734302, 36)\n",
      "(10794, 9.945325189734302, 36)\n",
      "(5424, 9.945325189734302, 36)\n",
      "(214, 9.945325189734302, 36)\n",
      "(5504, 9.945325189734302, 36)\n",
      "(5524, 9.945325189734302, 36)\n",
      "(10924, 9.945325189734302, 36)\n",
      "(11024, 9.945325189734302, 36)\n",
      "(11144, 9.945325189734302, 36)\n",
      "(5775, 9.945325189734302, 36)\n",
      "(5852, 9.945325189734302, 36)\n",
      "(650, 9.945325189734302, 36)\n",
      "(660, 9.945325189734302, 36)\n",
      "(671, 9.945325189734302, 36)\n",
      "(5911, 9.945325189734302, 36)\n",
      "(11333, 9.945325189734302, 36)\n",
      "(5955, 9.945325189734302, 36)\n"
     ]
    }
   ],
   "source": [
    "top_cafe = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n",
    "\n",
    "print('TOP recommended cafe (with more than 25 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, top_cafe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('5610000104201100078', 9.945325189734302), ('3760000104201100041', 9.945325189734302), ('3860000104201233744', 9.945325189734302)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('3860000104201900035', (9.945325189734302, '카페베이직(CafeBasic)')),\n",
       " ('3770000104202000044', (9.945325189734302, '오늘도빙수')),\n",
       " ('3760000104201100041', (9.945325189734302, '보그너커피')),\n",
       " ('3770000104200600061', (9.945325189734302, '할리스동수원점')),\n",
       " ('3770000104201900040', (9.945325189734302, '하루(HARU)')),\n",
       " ('3840000104201200010', (9.945325189734302, '에스케이카페(기념관점)')),\n",
       " ('3860000104201800159', (9.945325189734302, '라잌커피(coffee)')),\n",
       " ('3760000104201900008', (9.945325189734302, '워나로스터즈')),\n",
       " ('5610000104201500215', (9.945325189734302, '앨리스커피')),\n",
       " ('3770000104201800060', (9.945325189734302, '카페델로')),\n",
       " ('3810000104201500011', (9.945325189734302, '아이키친')),\n",
       " ('3790000104201800065', (9.945325189734302, '위클리커피')),\n",
       " ('3760000104201800069', (9.945325189734302, '세븐일레븐')),\n",
       " ('3810000104201600187', (9.945325189734302, '쥬씨 분당상록점')),\n",
       " ('3860000104201700203', (9.945325189734302, '카페늘봄')),\n",
       " ('3760000104201400142', (9.945325189734302, '엔젤리너스')),\n",
       " ('3800000104201500065', (9.945325189734302, '커피샵(#)')),\n",
       " ('3820000104201800082', (9.945325189734302, 'Aube 오브')),\n",
       " ('3860000104201233744', (9.945325189734302, '카페152')),\n",
       " ('3760000104201800074', (9.945325189734302, '카페드파리 롯데백화점 수원점')),\n",
       " ('3860000104201031301', (9.945325189734302, '이디야커피 부천중동점')),\n",
       " ('3860000104201700405', (9.945325189734302, '빈스빈스부천만화박물관점')),\n",
       " ('3850000104201500024', (9.945325189734302, '마성떡볶이')),\n",
       " ('5610000104201100078', (9.945325189734302, '삼성웰스토리(주)전기수원2파크웰스토리카페')),\n",
       " ('3750000104201700029', (9.945325189734302, '알콩달콩커피'))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topcafe_with_managenum = sc.parallelize(top_cafe).join(int_item)\n",
    "topcafe_managenum = topcafe_with_managenum.map(lambda tokens: (tokens[1][1], tokens[1][0]))\n",
    "print(topcafe_managenum.take(3))\n",
    "topcafe_managenum.join(cafe_data).take(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "\n",
    "model_path = os.path.join('..', 'models', 'cafe_lens_als')\n",
    "\n",
    "model.save(sc, model_path)\n",
    "same_model = MatrixFactorizationModel.load(sc, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
